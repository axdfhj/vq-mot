python3 train.py  \
--exp-name h36m_wrong \
--batch-size 128 \
--nb-code 512 \
--resume-pth /HOME/lyh/T2M-GPT/output/h36m_wrong/net_best_fid.pth \
--vq-name VQVAE_h36m_wrong \
--out-dir experiments \
--lr-scheduler 150000 \
--lr 1.5e-5 \
--weight-decay 4.5e-2 \
--dataname t2m \
--down-t 2 \
--depth 3 \
--quantizer ema_reset \
--dilation-growth-rate 3 \
--vq-act relu \
--epoch 800 \
--h36m \
--nodebug